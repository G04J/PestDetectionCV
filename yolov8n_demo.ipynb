{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u2S6KJeTNMj"
      },
      "source": [
        "# **Starter Code**\n",
        "- Imports\n",
        "- Checking GPU availability\n",
        "- Getting the Kaggle set and description of the download\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_oCJdJUR9fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install -q ultralytics kagglehub pyyaml opencv-python efficientnet_pytorch torch torchvision\n",
        "import torch\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import pathlib\n",
        "import yaml\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4B_5ChgSSNj"
      },
      "outputs": [],
      "source": [
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():     # Check for T4 availability on Colab (DON'T CHANGE)\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU detected. Go to Runtime -> Change runtime type ->  GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1bGCMx-SXD8"
      },
      "outputs": [],
      "source": [
        "\n",
        "path = kagglehub.dataset_download(\"rupankarmajumdar/crop-pests-dataset\")      # Getting the DATASET from kagglehub via CLI API (see their website - DON'T CHANGE)\n",
        "\n",
        "local_path = pathlib.Path(\"/content/datasets/crop-pests\")     # Saved the images to a local path to increase efficiency\n",
        "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, local_path, dirs_exist_ok=True)\n",
        "\n",
        "data_yaml_path = local_path / \"data.yaml\"     # YAML CONGIF (DON'T CHANGE)\n",
        "data_cfg = {\n",
        "    \"path\": str(local_path),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\":   \"valid/images\",\n",
        "    \"test\":  \"test/images\",\n",
        "    \"nc\": 12,\n",
        "    \"names\":\n",
        "     [\n",
        "      \"Ants\",\n",
        "      \"Bees\",\n",
        "      \"Beetles\",\n",
        "      \"Catterpillars\",     # NOTE: HAD TO CHANGE SPELLING BECAUSE DATASET IMAGES ARE SPELT LIKE THIS\n",
        "      \"Earthworms\",\n",
        "      \"Earwigs\",\n",
        "      \"Grasshoppers\",\n",
        "      \"Moths\",\n",
        "      \"Slugs\",\n",
        "      \"Snails\",\n",
        "      \"Wasps\",\n",
        "      \"Weevils\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f)\n",
        "\n",
        "\n",
        "# CHECKS\n",
        "num_train_images = len(list((local_path / \"train\" / \"images\").glob(\"*.jpg\")))\n",
        "num_val_images = len(list((local_path / \"valid\" / \"images\").glob(\"*.jpg\")))\n",
        "num_test_images = len(list((local_path / \"test\" / \"images\").glob(\"*.jpg\")))\n",
        "\n",
        "num_train_labels = len(list((local_path / \"train\" / \"labels\").glob(\"*.txt\")))\n",
        "num_val_labels = len(list((local_path / \"valid\" / \"labels\").glob(\"*.txt\")))\n",
        "num_test_labels = len(list((local_path / \"test\" / \"labels\").glob(\"*.txt\")))\n",
        "\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "print(f\"Number of validation images: {num_val_images}\")\n",
        "print(f\"Number of test images: {num_test_images}\")\n",
        "print(f\"Number of training labels: {num_train_labels}\")\n",
        "print(f\"Number of validation labels: {num_val_labels}\")\n",
        "print(f\"Number of test labels: {num_test_labels}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkuLvvScTcpn"
      },
      "source": [
        "# **Our Evaluation Metrics**\n",
        "- mAP@0.5 >= 0.5\n",
        "- mAP@0.5:0.95 (elps you detect over/under-sized bounding boxes)\n",
        "- Precision (false positive control)\n",
        "- Recall (false negative control)\n",
        "- F1 score\n",
        "- Training and Testing times\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0w3De9jVddK"
      },
      "outputs": [],
      "source": [
        "def base_evaluation_metrics(val_results):\n",
        "    metrics = val_results.results_dict\n",
        "    precision = metrics.get('metrics/precision(B)', 0)\n",
        "    recall    = metrics.get('metrics/recall(B)', 0)\n",
        "    mAP50     = metrics.get('metrics/mAP50(B)', 0)\n",
        "    mAP50_95  = metrics.get('metrics/mAP50-95(B)', 0)\n",
        "    f1_score  = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
        "    print(f\"\\nMean Average Precision (mAP@0.5):        {mAP50:.4f}\")\n",
        "    print(f\"Mean Average Precision (mAP@0.5:0.95):   {mAP50_95:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}  |  Recall: {recall:.4f}  |  F1-score: {f1_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9-hASZH932E"
      },
      "outputs": [],
      "source": [
        "def format_time(seconds):\n",
        "    mins, secs = divmod(seconds, 60)      # Converts total seconds into minutes and format.\n",
        "    return f\"{int(mins):0d}m {secs:.2f}s\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "292IC3EYJnSV"
      },
      "source": [
        "# DEMO: 15 EPOCH OPTIMSIED ON IMAGE DUPS AND AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSHm041wjIaB"
      },
      "outputs": [],
      "source": [
        "local_path = Path(\"/content/datasets/crop-pests\")     # Ensure local_path and names are defined\n",
        "data_yaml = yaml.safe_load(open(local_path / \"data.yaml\"))\n",
        "names = data_yaml[\"names\"]\n",
        "\n",
        "minority_classes = [\"Slugs\", \"Earthworms\", \"Beetles\", \"Catterpillars\", \"Earwigs\"]\n",
        "\n",
        "MAX_DUPLICATES = 1000\n",
        "SP_AMOUNT = 0.05\n",
        "SP_SALT_VS_PEPPER = 0.5\n",
        "\n",
        "\n",
        "def add_salt_and_pepper_noise(img, amount=0.05, salt_vs_pepper=0.5):\n",
        "    noisy = img.copy()\n",
        "    h, w = noisy.shape[:2]\n",
        "    num_pixels = h * w\n",
        "    num_salt = int(amount * num_pixels * salt_vs_pepper)\n",
        "    num_pepper = int(amount * num_pixels * (1 - salt_vs_pepper))\n",
        "\n",
        "    # Salt (white) noise\n",
        "    ys = np.random.randint(0, h, num_salt)\n",
        "    xs = np.random.randint(0, w, num_salt)\n",
        "    noisy[ys, xs] = 255\n",
        "\n",
        "    # Pepper (black) noise\n",
        "    ys = np.random.randint(0, h, num_pepper)\n",
        "    xs = np.random.randint(0, w, num_pepper)\n",
        "    noisy[ys, xs] = 0\n",
        "\n",
        "    return noisy\n",
        "\n",
        "\n",
        "minority_class_ids = [names.index(c) for c in minority_classes if c in names]       # Get the class IDs for minority classes\n",
        "\n",
        "duplicated_count = 0      # Make sure this exists even if no minority classes\n",
        "\n",
        "if not minority_class_ids:\n",
        "    print(\"No valid minority classes specified from the dataset names.\")\n",
        "else:\n",
        "    print(f\"Minority classes for duplication: {minority_classes}\")\n",
        "\n",
        "    train_images_dir = local_path / \"train\" / \"images\"\n",
        "    train_labels_dir = local_path / \"train\" / \"labels\"\n",
        "\n",
        "    # Create directories for duplicated images and labels\n",
        "    duplicated_images_dir = local_path / \"train\" / \"images_duplicated\"\n",
        "    duplicated_labels_dir = local_path / \"train\" / \"labels_duplicated\"\n",
        "\n",
        "    # Clean up previous runs if any\n",
        "    if duplicated_images_dir.exists():\n",
        "        shutil.rmtree(duplicated_images_dir)\n",
        "    if duplicated_labels_dir.exists():\n",
        "        shutil.rmtree(duplicated_labels_dir)\n",
        "\n",
        "    duplicated_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "    duplicated_labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    processed_images_count = 0\n",
        "\n",
        "    for label_file in train_labels_dir.glob(\"*.txt\"):\n",
        "        if duplicated_count >= MAX_DUPLICATES:      # Stop once we hit max duplicates\n",
        "            break\n",
        "\n",
        "        image_file = train_images_dir / f\"{label_file.stem}.jpg\"\n",
        "        if not image_file.exists():\n",
        "            continue\n",
        "\n",
        "        has_minority_class = False\n",
        "        try:\n",
        "            with open(label_file, 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if parts:\n",
        "                        class_id = int(parts[0])\n",
        "                        if class_id in minority_class_ids:\n",
        "                            has_minority_class = True\n",
        "                            break     # Found a minority class\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading label file {label_file}: {e}\")\n",
        "            continue      # Skip this file if there's an error\n",
        "\n",
        "        if has_minority_class:\n",
        "            processed_images_count += 1\n",
        "\n",
        "            new_image_name = f\"{image_file.stem}_dup{1}{image_file.suffix}\"\n",
        "            new_label_name = f\"{label_file.stem}_dup{1}{label_file.suffix}\"\n",
        "\n",
        "            new_image_path = duplicated_images_dir / new_image_name\n",
        "            new_label_path = duplicated_labels_dir / new_label_name\n",
        "\n",
        "            try:\n",
        "                img = cv2.imread(str(image_file))\n",
        "                if img is None:\n",
        "                    print(f\"Warning: Could not read image {image_file} for augmentation.\")\n",
        "                    continue\n",
        "\n",
        "                noisy_img = add_salt_and_pepper_noise(       # 1) Add salt-and-pepper noise\n",
        "                    img,\n",
        "                    amount=SP_AMOUNT,\n",
        "                    salt_vs_pepper=SP_SALT_VS_PEPPER\n",
        "                )\n",
        "\n",
        "                rotated_img = cv2.rotate(noisy_img, cv2.ROTATE_180)     # 2) Rotate 180 degrees\n",
        "\n",
        "\n",
        "                cv2.imwrite(str(new_image_path), rotated_img)\n",
        "                shutil.copy2(str(label_file), str(new_label_path))\n",
        "\n",
        "                duplicated_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error duplicating files for {image_file}: {e}\")\n",
        "# CHECK\n",
        "print(f\"Total Duplicates: {duplicated_count}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy67vcwiu8fr"
      },
      "outputs": [],
      "source": [
        "# Generate Training File List Including Duplicated Images (No Copying)\n",
        "\n",
        "original_train_images_dir = local_path / \"train\" / \"images\"\n",
        "# This is for duplicates\n",
        "duplicated_images_dir = local_path / \"train\" / \"images_duplicated\"\n",
        "\n",
        "train_file_list_path = local_path / \"train_images_list.txt\"\n",
        "\n",
        "all_train_image_paths = []\n",
        "\n",
        "if original_train_images_dir.exists():\n",
        "    print(f\"Collecting images from: {original_train_images_dir}\")\n",
        "    all_train_image_paths.extend([str(p.resolve()) for p in original_train_images_dir.glob(\"*.jpg\")])     # Collect original image paths\n",
        "else:\n",
        "    print(f\"Warning: Original training images directory not found at {original_train_images_dir}\")\n",
        "\n",
        "if duplicated_images_dir.exists():\n",
        "    print(f\"Collecting images from: {duplicated_images_dir}\")\n",
        "    all_train_image_paths.extend([str(p.resolve()) for p in duplicated_images_dir.glob(\"*.jpg\")])\n",
        "else:\n",
        "    print(f\"Warning: Duplicated images directory not found at {duplicated_images_dir}\")     # Collect duplicated image paths\n",
        "\n",
        "with open(train_file_list_path, \"w\") as f:\n",
        "    for img_path in all_train_image_paths:      # Write the file list to a text file\n",
        "        f.write(f\"{img_path}\\n\")\n",
        "\n",
        "print(f\"\\nGenerated training image file list at: {train_file_list_path}\")\n",
        "print(f\"Total images included in the file list: {len(all_train_image_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHOKS3Scu9KU"
      },
      "outputs": [],
      "source": [
        "# Update data.yaml to Use the Training File List\n",
        "\n",
        "data_yaml_path = local_path / \"data.yaml\"\n",
        "\n",
        "if data_yaml_path.exists():\n",
        "    with open(data_yaml_path, \"r\") as f:      # Load the existing data.yaml content\n",
        "        data_cfg = yaml.safe_load(f)\n",
        "else:\n",
        "    print(f\"Warning: data.yaml not found at {data_yaml_path}. Creating a new one.\")\n",
        "    data_cfg = {\n",
        "        \"path\": str(local_path), # Keep the root path for val/test\n",
        "        \"val\":   \"valid/images\",\n",
        "        \"test\":  \"test/images\",\n",
        "        \"nc\": 12,\n",
        "        \"names\":\n",
        "         [\n",
        "          \"Ants\",\n",
        "          \"Bees\",\n",
        "          \"Beetles\",\n",
        "          \"Catterpillars\",\n",
        "          \"Earthworms\",\n",
        "          \"Earwigs\",\n",
        "          \"Grasshoppers\",\n",
        "          \"Moths\",\n",
        "          \"Slugs\",\n",
        "          \"Snails\",\n",
        "          \"Wasps\",\n",
        "          \"Weevils\",\n",
        "        ]\n",
        "    }\n",
        "\n",
        "data_cfg[\"train\"] = str(train_file_list_path.resolve())\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:      # Write the updated data.yaml file\n",
        "    yaml.safe_dump(data_cfg, f)\n",
        "\n",
        "\n",
        "print(yaml.safe_dump(data_cfg))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx9FWQJgvQoL"
      },
      "outputs": [],
      "source": [
        " # OPTIMISED 15 EPOCH: CHOSEN\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "start = time.time()\n",
        "train_res = model.train(\n",
        "    data=str(local_path/\"data.yaml\"),     # Use the data.yaml file which now points to the training image file list\n",
        "    epochs=15,\n",
        "    imgsz=512,\n",
        "    mosaic=1.0,\n",
        "    batch=-1,\n",
        "    device=0,\n",
        "    project=\"pests_fast\",\n",
        "    name=\"yolov8n_colab\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "\n",
        "start = time.time()\n",
        "val_results = model.val(\n",
        "    data=str(local_path/\"data.yaml\"),\n",
        "    split=\"test\",\n",
        "    batch=16,\n",
        "    iou=0.5,\n",
        "    device=0,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "val_time = end - start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwFS0w49vcdf"
      },
      "outputs": [],
      "source": [
        "sample_dir = local_path / \"test\" / \"images\"\n",
        "test_res = model.predict(\n",
        "    source=str(sample_dir),\n",
        "    imgsz=512,\n",
        "    conf=0.25,\n",
        "    device=0,\n",
        "    save=True,\n",
        "    project=\"runs/detect\",\n",
        "    name=\"pest_predictions\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0N3czRp76QE"
      },
      "outputs": [],
      "source": [
        "IMGSZ = 512\n",
        "UPSCALE = 6\n",
        "BOX_SCALE = 6\n",
        "TITLE_FONTSIZE = 22\n",
        "TEXT_FONTSIZE = 16\n",
        "\n",
        "# Paths\n",
        "test_img_dir = local_path / \"test\" / \"images\"\n",
        "test_lbl_dir = local_path / \"test\" / \"labels\"\n",
        "\n",
        "# Class names\n",
        "with open(local_path / \"data.yaml\") as f:\n",
        "    data_cfg = yaml.safe_load(f)\n",
        "class_names = data_cfg[\"names\"]\n",
        "\n",
        "\n",
        "def draw_boxes(img, boxes, color, scale=BOX_SCALE):\n",
        "    thickness = 2 * scale\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "\n",
        "def load_gt_boxes(label_path, image_weight, image_height):\n",
        "    gt_boxes = []\n",
        "    gt_classes = []\n",
        "    if not label_path.exists():\n",
        "        return gt_boxes, gt_classes\n",
        "\n",
        "    with open(label_path) as f:\n",
        "        for line in f:\n",
        "            cid, xc, yc, bw, bh = map(float, line.split())\n",
        "            x1 = (xc - bw/2) * image_weight\n",
        "            y1 = (yc - bh/2) * image_height\n",
        "            x2 = (xc + bw/2) * image_weight\n",
        "            y2 = (yc + bh/2) * image_height\n",
        "            gt_boxes.append([x1, y1, x2, y2])\n",
        "            gt_classes.append(int(cid))\n",
        "    return gt_boxes, gt_classes\n",
        "\n",
        "test_res = model.predict(\n",
        "    source=str(test_img_dir),\n",
        "    imgsz=IMGSZ,\n",
        "    conf=0.25,\n",
        "    device=0,\n",
        "    save=False,\n",
        "    verbose=False\n",
        ")\n",
        "pred_map = { Path(r.path).name: r for r in test_res }\n",
        "\n",
        "# Show 5 per class picked randomly\n",
        "for cls_id, cls_name in enumerate(class_names):\n",
        "    # Find test images with this class\n",
        "    candidate_images = []\n",
        "    for lbl_file in test_lbl_dir.glob(\"*.txt\"):\n",
        "        with open(lbl_file) as f:\n",
        "            if any(int(line.split()[0]) == cls_id for line in f):\n",
        "                candidate_images.append(lbl_file.stem + \".jpg\")\n",
        "\n",
        "    if not candidate_images:\n",
        "        print(f\"No images for class {cls_name}\")\n",
        "        continue\n",
        "\n",
        "    sample_imgs = random.sample(candidate_images, k=min(5, len(candidate_images)))\n",
        "\n",
        "    for img_name in sample_imgs:\n",
        "\n",
        "        # Load & upscale\n",
        "        img_path = test_img_dir / img_name\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, None, fx=UPSCALE, fy=UPSCALE, interpolation=cv2.INTER_NEAREST)\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        # Ground Truth box in red\n",
        "        label_path = test_lbl_dir / (Path(img_name).stem + \".txt\")\n",
        "        gt_boxes, gt_classes = load_gt_boxes(label_path, w, h)\n",
        "        draw_boxes(img, np.array(gt_boxes), (255, 0, 0), scale=BOX_SCALE)\n",
        "\n",
        "        gt_text = \", \".join([class_names[c] for c in gt_classes]) or \"None\"\n",
        "\n",
        "        # Prediction box in blue\n",
        "        pred = pred_map.get(img_name, None)\n",
        "        pred_boxes = []\n",
        "        pred_text = \"None\"\n",
        "\n",
        "        if pred is not None and pred.boxes is not None:\n",
        "            pred_boxes = (pred.boxes.xyxy.cpu().numpy() * UPSCALE)\n",
        "            pred_classes = [int(b.cls) for b in pred.boxes]\n",
        "            pred_confs = [float(b.conf) for b in pred.boxes]\n",
        "            pred_text = \", \".join([\n",
        "                f\"{class_names[c]} ({conf:.2f})\"\n",
        "                for c, conf in zip(pred_classes, pred_confs)\n",
        "            ])\n",
        "\n",
        "        draw_boxes(img, pred_boxes, (0, 0, 255), scale=BOX_SCALE)\n",
        "        plt.figure(figsize=(7, 7))\n",
        "        plt.suptitle(f\"{cls_name} â€” Example (GT=Red, Pred=Blue)\", fontsize=TITLE_FONTSIZE, fontweight='bold')\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.figtext(      # Classification text outside image\n",
        "            0.5, -0.05,\n",
        "            f\"GT: {gt_text}\\nPredicted: {pred_text}\",\n",
        "            ha=\"center\",\n",
        "            fontsize=TEXT_FONTSIZE\n",
        "        )\n",
        "\n",
        "        plt.show()\n",
        "        print(\"-----------------------------------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
